{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe227ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import urllib.request as ur\n",
    "\n",
    "\n",
    "def search_information(name,page_n):\n",
    "\n",
    "    df_dic = {}\n",
    "    dic_keys = ['title']\n",
    "    \n",
    "    url = 'https://github.com/orgs/{}/repositories?page={}'.format(name,page_n)\n",
    "\n",
    "    html = ur.urlopen(url)\n",
    "    soup = bs(html.read(), \"html.parser\")\n",
    "\n",
    "    # 이름,별점,블로그,방문자 리뷰\n",
    "    repository_list = soup.find_all(\"li\", \"Box-row\") # 제목\n",
    "    # print(len(repository_list)) # 한페이지당 30개의 repository가 존재 (full일 때)\n",
    "\n",
    "\n",
    "    for k in dic_keys:\n",
    "        df_dic[k] = []\n",
    "\n",
    "    for repo in repository_list:\n",
    "        title = repo.find('a','d-inline-block').text.strip() # 각 repository별 title 추출\n",
    "\n",
    "\n",
    "        df_dic['title'].append(title)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return pd.DataFrame(df_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf99de47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 1)\n",
      "14.698469161987305  second\n"
     ]
    }
   ],
   "source": [
    "def main(name):\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "            columns=[\n",
    "                \"title\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for i in range(1,16): # 한 페이지당 repo 30개씩 추출 가능 \n",
    "        temp_df = search_information(name,i) #search_information 함수 사용\n",
    "\n",
    "        df = pd.concat([df,temp_df],ignore_index=True) #여러개의 동일한 형태 DataFrame 합치기 -> 각 페이지 데이터프레임 형태 합침\n",
    "    return df\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    start = time.time()\n",
    "    result_df = main('NVIDIA')\n",
    "    end = time.time()\n",
    "    print(result_df.shape)\n",
    "    print(end - start, \" second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f235af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       title\n",
      "0           spark-rapids-jni\n",
      "1    spark-rapids-benchmarks\n",
      "2                       DALI\n",
      "3                       NeMo\n",
      "4            cheminformatics\n",
      "..                       ...\n",
      "303                  scenejs\n",
      "304                      tdl\n",
      "305               cdt-nsight\n",
      "306               ptp-nsight\n",
      "307               gef-nsight\n",
      "\n",
      "[308 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc9effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time  # 시간 데이터 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00ac4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning time :  137.97776794433594\n"
     ]
    }
   ],
   "source": [
    "# https://api.github.com/repos/nvidia/nemo\n",
    "from collections import defaultdict #딕셔너리를 만드는 dict클래스의 서브 클래스\n",
    "\n",
    "urls = [[i,f\"https://api.github.com/repos/nvidia/{i}\"] for i in result_df['title']]\n",
    "dic = defaultdict(str)\n",
    "\n",
    "# PAT(Personnal Access Token)을 발급받아 1시간에 60개에서 5000개로 요청한도를 늘린다\n",
    "headers = { \"Authorization\": \"token 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\"} \n",
    "s = time.time()\n",
    "\n",
    "for i,url in urls:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    create_date = response.json().get('created_at')\n",
    "    dic[i] = create_date\n",
    "#     print(dic[i])\n",
    "print('learning time : ',time.time()-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab0e1052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2012-05-10T22:29:32Z'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "db350bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Title              Creat_at\n",
      "0           spark-rapids-jni  2022-01-12T16:24:11Z\n",
      "1    spark-rapids-benchmarks  2022-05-24T19:23:10Z\n",
      "2                       DALI  2018-06-01T22:18:01Z\n",
      "3                       NeMo  2019-08-05T20:16:42Z\n",
      "4            cheminformatics  2020-09-30T16:27:59Z\n",
      "..                       ...                   ...\n",
      "303                  scenejs  2014-06-05T15:32:25Z\n",
      "304                      tdl  2014-02-25T10:38:49Z\n",
      "305               cdt-nsight  2011-08-24T21:07:25Z\n",
      "306               ptp-nsight  2013-06-13T23:11:09Z\n",
      "307               gef-nsight  2012-05-10T22:29:32Z\n",
      "\n",
      "[308 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(list(dic.items()),\n",
    "                   columns=['Title', 'Creat_at']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d448d839",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (308, 1), indices imply (308, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCreat_at\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/crawling/lib/python3.9/site-packages/pandas/core/frame.py:737\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    729\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    730\u001b[0m             arrays,\n\u001b[1;32m    731\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    734\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 737\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    747\u001b[0m         {},\n\u001b[1;32m    748\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    751\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    752\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/crawling/lib/python3.9/site-packages/pandas/core/internals/construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    347\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    348\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    349\u001b[0m )\n\u001b[0;32m--> 351\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/crawling/lib/python3.9/site-packages/pandas/core/internals/construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    420\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    421\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 422\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (308, 1), indices imply (308, 2)"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(list(dic),\n",
    "                   columns=['Title', 'Creat_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9509afdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Creat_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spark-rapids-jni</td>\n",
       "      <td>2022-01-12T16:24:11Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spark-rapids-benchmarks</td>\n",
       "      <td>2022-05-24T19:23:10Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DALI</td>\n",
       "      <td>2018-06-01T22:18:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeMo</td>\n",
       "      <td>2019-08-05T20:16:42Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cheminformatics</td>\n",
       "      <td>2020-09-30T16:27:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>scenejs</td>\n",
       "      <td>2014-06-05T15:32:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>tdl</td>\n",
       "      <td>2014-02-25T10:38:49Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>cdt-nsight</td>\n",
       "      <td>2011-08-24T21:07:25Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ptp-nsight</td>\n",
       "      <td>2013-06-13T23:11:09Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>gef-nsight</td>\n",
       "      <td>2012-05-10T22:29:32Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title              Creat_at\n",
       "0           spark-rapids-jni  2022-01-12T16:24:11Z\n",
       "1    spark-rapids-benchmarks  2022-05-24T19:23:10Z\n",
       "2                       DALI  2018-06-01T22:18:01Z\n",
       "3                       NeMo  2019-08-05T20:16:42Z\n",
       "4            cheminformatics  2020-09-30T16:27:59Z\n",
       "..                       ...                   ...\n",
       "303                  scenejs  2014-06-05T15:32:25Z\n",
       "304                      tdl  2014-02-25T10:38:49Z\n",
       "305               cdt-nsight  2011-08-24T21:07:25Z\n",
       "306               ptp-nsight  2013-06-13T23:11:09Z\n",
       "307               gef-nsight  2012-05-10T22:29:32Z\n",
       "\n",
       "[308 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff68a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Crawling",
   "language": "python",
   "name": "crawling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
